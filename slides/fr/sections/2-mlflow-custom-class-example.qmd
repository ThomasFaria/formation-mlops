## Contexte

- Code [**APE**]{.orange}
  - Nomenclature statistique des [**Activités économiques**]{.blue2} dans la Communauté Européenne
  - [**Structure hierarchique**]{.blue2} (NACE) avec 5 niveaux et  732 codes

- A l'Insee, précédemment classifié par un algorithme basé sur des [**règles de décisions**]{.orange} 

- [**Problématique commune**]{.orange} à beaucoup d'Instituts nationaux de statistique

## Le modèle FastText {background-image="../img/diag-fasttext.png" background-size="90%" background-position="50% 90%"}

::: {.nonincremental}

- [**Modèle "sac de n-gram"**]{.orange} : plongements lexicaux pour les mots mais aussi pour les n-gram de mots et de caractères

- Un modèle très [**simple**]{.orange} et [**rapide**]{.orange}

:::

[OVA: One vs. All]{.absolute bottom=20 left=-200 }

## Données utilisées {.scrollable}

::: {.panel-tabset}

### Données 

- Un cas d'utilisation simple avec seulement [**2 variables**]{.orange} :
  - [Description textuelle]{.blue2} de l'activité - [text]{.green2}
  - [**Code APE vrai**]{.blue2} labelisé par le moteur de règles – [nace]{.green2} (732 modalités)

- [**Prétraitements**]{.orange} standards :
  - Passage en minuscules
  - Suppression de la ponctuation
  - Suppression des nombres
  - Suppression des mots vide de sens
  - Racinisation (stemming)
  - ...


### Brutes

```{ojs}
viewof table_data = Inputs.table(transpose(data_raw), {
    rows: 22
})
```

### Pré-traitée

```{ojs}
viewof table_data_prepro = Inputs.table(transpose(data_prepro), {
    rows: 22
})
```

:::

## MLflow avec framework non standard

::: {.nonincremental}

:::: {.fragment fragment-index=1}
- [**Facile d'utilisation**]{.orange} avec une grande variété de *framework de machine learning* (scikit-learn, Keras, Pytorch...) 
::::

:::: {.fragment fragment-index=2}
```python
mlflow.sklearn.log_model(pipe_rf, "model")

mlflow.pyfunc.load_model(model_uri=f"models:/{model_name}/{version}")
y_train_pred = model.predict(X_train)

```
::::

:::: {.fragment fragment-index=3}
- Que se passe-t-il si nous avons besoin d'une plus grande [**flexibilité**]{.orange}, par exemple, pour utiliser un [**framework personnalisé**]{.orange}?
::::

:::: {.fragment fragment-index=4}
- Possibilité de [**suivre**]{.orange}, [**enregistrer**]{.orange} et [**déployer**]{.orange} son propre modèle
::::

:::

## MLflow avec framework non standard

::: {.nonincremental}

:::: {.fragment fragment-index=1}
- il y a [**2 principales différences**]{.orange} lorsque vous utilisez votre propre framework:
  - [**L'enregistrement**]{.blue2} des paramètres, des métriques et des artefacts
  - [**L'encapsulation**]{.blue2} de votre modèle personalisé afin que MLflow puisse le servir
::::

:::: {.fragment fragment-index=2}
```python
# Define a custom model
class MyModel(mlflow.pyfunc.PythonModel):

    def load_context(self, context):
        self.my_model.load_model(context.artifacts["my_model"])

    def predict(self, context, model_input):
        return self.my_model.predict(model_input)
```
::::

:::

<!-- By creating a class that inherits from mlflow.pyfunc.PythonModel, you are essentially creating a wrapper around your custom model that allows it to be used with the MLflow platform. The mlflow.pyfunc.PythonModel class provides a standardized interface that makes it easy to integrate your custom model with the rest of the MLflow platform. -->

## De l'expérimentation à la production

- Les notebooks ne sont pas adaptés pour une [**mise en production**]{.orange} de modèles *ML* :
  - Potentiel limité d'[**automatisation**]{.blue2} des pipelines *ML*.
  - Workflows peu clairs et peu [**reproductible**]{.blue2}.
  - Limite la [**collaboration**]{.blue2} et le [**contrôle de version**]{.blue2} entre les membres de l'équipe.
  - [**Modularité**]{.blue2} insuffisante pour gérer des composants *ML* complexe.


```{python}
#| cache: false
import sys
sys.path.append("../../src/")

import pandas as pd
import s3fs
import pyarrow.parquet as pq
from constants import TEXT_FEATURE, DATA_PATH
from preprocessor import Preprocessor

preprocessor = Preprocessor()
fs = s3fs.S3FileSystem(
    client_kwargs={"endpoint_url": "https://minio.lab.sspcloud.fr"}
)
df = pq.ParquetDataset(DATA_PATH, filesystem=fs).read_pandas().to_pandas()
df = df.sample(frac=0.001, random_state=0)

df_prepro = preprocessor.clean_text(df, TEXT_FEATURE)

ojs_define(data_raw = df, data_prepro = df_prepro)
```
